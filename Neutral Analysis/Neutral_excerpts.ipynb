{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13206054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import sys\n",
    "sys.path.append(\"C:\\\\Users\\\\tiago\\\\OneDrive - Universidade de Aveiro\\\\3- Data Collection1\")\n",
    "import pickle\n",
    "import neurokit2 as nk\n",
    "\n",
    "# Acessing files functions\n",
    "from reading_function import *\n",
    "from stationarity_function import *\n",
    "from neurokit_function import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c73862",
   "metadata": {},
   "source": [
    "## Dividing Neutral signals in excerpts (2min each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2a532ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_data_S1 = pickle.load(open('dict_data_S1_file', 'rb'))\n",
    "dict_emotion_S1 = pickle.load(open('dict_emotion_S1_file', 'rb'))\n",
    "sampling_rate = 1000\n",
    "dict_data_S2 = pickle.load(open('dict_data_S2_file', 'rb'))\n",
    "dict_emotion_S2 = pickle.load(open('dict_emotion_S2_file', 'rb'))\n",
    "sampling_rate = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a356e216",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_split_S1 = dict_emotion_S1\n",
    "dict_split_S2 = dict_emotion_S2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9acec1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spliting_signals (signal, sampling_rate):\n",
    "    \n",
    "    size = len(signal)\n",
    "    \n",
    "    splits = {}\n",
    "    \n",
    "    increment = round(size/5)\n",
    "    \n",
    "    for i in range (0, 5):\n",
    "        st = i* increment\n",
    "        en = (i+1)*increment\n",
    "        small_signal = signal[st:en]\n",
    "        splits[i+1]=small_signal\n",
    "               \n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bab17cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spliting_emotion (Emotion, dict_split, sampling_rate):\n",
    "    \n",
    "    for part in dict_split[Emotion][0]:\n",
    "        signal = dict_split[Emotion][0][part]\n",
    "        splits = spliting_signals (signal, sampling_rate)\n",
    "        dict_split[Emotion][0][part] = splits\n",
    "        \n",
    "    return dict_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daed46d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_split_S1 = spliting_emotion ('Neutral', dict_split_S1, sampling_rate)\n",
    "dict_split_S2 = spliting_emotion ('Neutral', dict_split_S2, sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ad5fe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( dict_split_S1, open( \"dict_split_S1\", \"wb\" ) )\n",
    "pickle.dump( dict_split_S2, open( \"dict_split_S2\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "342bd804",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_split_S1 = pickle.load( open( \"dict_split_S1\", \"rb\" ) )\n",
    "sampling_rate=1000\n",
    "dict_split_S2 = pickle.load( open( \"dict_split_S2\", \"rb\" ) )\n",
    "sampling_rate=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511f93e8",
   "metadata": {},
   "source": [
    "#### Preprocesing signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d2608ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_preprocessed_features (dict_emotion, condition, sampling_rate):\n",
    "    \n",
    "    dic_features={}\n",
    "        \n",
    "    for part in dict_emotion[condition][0].keys():\n",
    "        #print(part)\n",
    "        dic_features[part]={}\n",
    "        \n",
    "        for split in dict_emotion[condition][0][part].keys():\n",
    "            \n",
    "            if (condition=='Fear') & (part=='C007') & (split==5):\n",
    "                a = 118629\n",
    "                b = len(dict_emotion[condition][0][part][split][:,1])\n",
    "                \n",
    "            elif (condition=='Fear') & (part=='C011') & (split==1):\n",
    "                a=118534\n",
    "                b = len(dict_emotion[condition][0][part][split][:,1])\n",
    "            \n",
    "            elif (condition=='Happy') & (part=='C008') & (split==4):\n",
    "                a=121243\n",
    "                b = len(dict_emotion[condition][0][part][split][:,1])\n",
    "            \n",
    "            elif (condition=='Happy') & (part=='C026') & (split==5):\n",
    "                a=119540\n",
    "                b = len(dict_emotion[condition][0][part][split][:,1])\n",
    "                \n",
    "            elif (condition=='Neutral') & (part=='C010') & (split==2):    \n",
    "                a=len(dict_emotion[condition][0][part][split][:,0])\n",
    "                b=131074\n",
    "                \n",
    "            elif (condition=='Neutral') & (part=='C014') & (split==5):\n",
    "                a=132533\n",
    "                b = len(dict_emotion[condition][0][part][split][:,1])\n",
    "                \n",
    "            else:\n",
    "                a = len(dict_emotion[condition][0][part][split][:,0])\n",
    "                b = len(dict_emotion[condition][0][part][split][:,1])\n",
    "            \n",
    "            #print(split)\n",
    "            \n",
    "            # Features\n",
    "            MF_duration_activity, MF_peak_activity, MF_mean_activity, MF_area_activity, MF_amplitude_activity = signal_process (dict_emotion[condition][0][part][split][:,0], 'EMG', sampling_rate, a)\n",
    "            TR_duration_activity, TR_peak_activity, TR_mean_activity, TR_area_activity, TR_amplitude_activity = signal_process (dict_emotion[condition][0][part][split][:,1], 'EMG', sampling_rate, b)\n",
    "            eda_symp, scr_height, scr_amplitude, scr_risetime, scr_recoverytime, eda_tonic, eda_phasic = signal_process (dict_emotion[condition][0][part][split][:,2], 'EDA', sampling_rate, len(dict_emotion[condition][0][part][split][:,2]))\n",
    "            ecg_Rpeaks, ecg_rate, t_duration = signal_process (dict_emotion[condition][0][part][split][:,3], 'ECG', sampling_rate, len(dict_emotion[condition][0][part][split][:,3]))\n",
    "    \n",
    "            dic_features[part][split]={'MF_duration_activity':MF_duration_activity,'MF_peak_activity':MF_peak_activity,\n",
    "                                              'MF_mean_activity':MF_mean_activity,'MF_area_activity':MF_area_activity,\n",
    "                                              'MF_amplitude_activity':MF_amplitude_activity,\n",
    "                                              'TR_duration_activity':TR_duration_activity,'TR_peak_activity':TR_peak_activity,\n",
    "                                              'TR_mean_activity':TR_mean_activity,'TR_area_activity':TR_area_activity,\n",
    "                                              'TR_amplitude_activity':TR_amplitude_activity,\n",
    "                                              'scr_height':scr_height,'scr_amplitude':scr_amplitude,'scr_risetime':scr_risetime,\n",
    "                                              'scr_recoverytime':scr_recoverytime, 'eda_tonic':eda_tonic, 'eda_phasic':eda_phasic,\n",
    "                                              'ecg_rate':ecg_rate,'t_duration':t_duration,\n",
    "                                              'eda_symp':eda_symp, 'ecg_Rpeaks':ecg_Rpeaks}\n",
    "      \n",
    "    return dic_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f7ca38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tiago\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\tiago\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\tiago\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\tiago\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\tiago\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\tiago\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\tiago\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\tiago\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\tiago\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\tiago\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\tiago\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\tiago\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\tiago\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\tiago\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "dict_split_neutral_S1 = all_preprocessed_features (dict_split_S1, 'Neutral', sampling_rate)\n",
    "dict_split_neutral_S2 = all_preprocessed_features (dict_split_S2, 'Neutral', sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6686e779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating files with Session 1 relevant information to keep:\n",
    "filename_S1 = 'dict_split_neutral_S1'\n",
    "file_S1 = open(filename_S1,'wb')\n",
    "pickle.dump(dict_split_neutral_S1,file_S1)\n",
    "file_S1.close()\n",
    " \n",
    "# Creating files with Session 2 relevant information to keep:\n",
    "filename_S2 = 'dict_split_neutral_S2'\n",
    "file_S2 = open(filename_S2,'wb')\n",
    "pickle.dump(dict_split_neutral_S2,file_S2)\n",
    "file_S2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935d16b2",
   "metadata": {},
   "source": [
    "#### Acessing preprocessed splited data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b58d35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_split_neutral_S1 = pickle.load(open('dict_split_neutral_S1', 'rb'))\n",
    "dict_split_neutral_S2 = pickle.load(open('dict_split_neutral_S2', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fd0498",
   "metadata": {},
   "source": [
    "#### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b98e5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_features (dic_features, sampling_rate):\n",
    "    lista=[]\n",
    "        \n",
    "    for participant in dic_features.keys():  \n",
    "        \n",
    "        for split in dic_features[participant].keys():\n",
    "        \n",
    "            # Features\n",
    "            features_emg_mf = feature_extraction (dic_features[participant][split], 'EMG_MF', sampling_rate)\n",
    "            features_emg_tr = feature_extraction (dic_features[participant][split], 'EMG_TR', sampling_rate)\n",
    "            features_eda = feature_extraction (dic_features[participant][split], 'EDA', sampling_rate)\n",
    "            features_ecg = feature_extraction (dic_features[participant][split], 'ECG', sampling_rate)\n",
    "    \n",
    "            part=pd.DataFrame({'ID participant':[participant], 'Excerpt':[split]})\n",
    "            features_=pd.concat([part, features_emg_mf, features_emg_tr, features_eda, features_ecg],axis=1)\n",
    "            lista.append(features_)    \n",
    "      \n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba9db0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tiago\\OneDrive - Universidade de Aveiro\\3- Data Collection1\\neurokit_function.py:206: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  skewness = (3*(mean-np.nanmedian(a)))/standard_deviation\n",
      "C:\\Users\\tiago\\OneDrive - Universidade de Aveiro\\3- Data Collection1\\neurokit_function.py:206: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  skewness = (3*(mean-np.nanmedian(a)))/standard_deviation\n",
      "C:\\Users\\tiago\\AppData\\Local\\Temp\\ipykernel_18476\\3385887210.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  neutral_s1_features_df = neutral_s1_df.append(other=neutral_s1_features,ignore_index=True)\n",
      "C:\\Users\\tiago\\AppData\\Local\\Temp\\ipykernel_18476\\3385887210.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  neutral_s2_features_df = neutral_s2_df.append(other=neutral_s2_features,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "neutral_s1_features = all_features(dict_split_neutral_S1, sampling_rate)\n",
    "neutral_s1_df = pd.DataFrame()\n",
    "neutral_s1_features_df = neutral_s1_df.append(other=neutral_s1_features,ignore_index=True)\n",
    "\n",
    "neutral_s2_features = all_features(dict_split_neutral_S2, sampling_rate)\n",
    "neutral_s2_df = pd.DataFrame()\n",
    "neutral_s2_features_df = neutral_s2_df.append(other=neutral_s2_features,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d711cdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_feat='neutral_features_excerpts_s1.xlsx'\n",
    "writer=pd.ExcelWriter(filepath_feat, engine='xlsxwriter')\n",
    "neutral_s1_features_df.to_excel(writer, sheet_name='neutral_s1', na_rep='nan')\n",
    "writer.save()\n",
    "\n",
    "filepath_feat='neutral_features_excerpts_s2.xlsx'\n",
    "writer=pd.ExcelWriter(filepath_feat, engine='xlsxwriter')\n",
    "neutral_s2_features_df.to_excel(writer, sheet_name='neutral_s2', na_rep='nan')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df63f883",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
